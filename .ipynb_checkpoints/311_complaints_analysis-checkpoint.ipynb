{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load the 311 complaints dataset available here https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "b'wc: ./311.csv: open: No such file or directory\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5_/1_r427cs3pzdt448p7rr_k5w0000gn/T/ipykernel_58648/2189067608.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mn_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mf'Exact number of rows: {n_rows}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mdf_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCSV_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/5_/1_r427cs3pzdt448p7rr_k5w0000gn/T/ipykernel_58648/2189067608.py\u001b[0m in \u001b[0;36mfile_len\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: b'wc: ./311.csv: open: No such file or directory\\n'"
     ]
    }
   ],
   "source": [
    "CSV_PATH = './data/311.csv'\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import pandas as pd \n",
    "import os\n",
    "from h3 import h3\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def file_len(fname):\n",
    "    p = subprocess.Popen(['wc', '-l', fname], stdout=subprocess.PIPE, \n",
    "                                              stderr=subprocess.PIPE)\n",
    "    result, err = p.communicate()\n",
    "    if p.returncode != 0:\n",
    "        raise IOError(err)\n",
    "    return int(result.strip().split()[0])+1\n",
    "\n",
    "n_rows = file_len(CSV_PATH)\n",
    "print (f'Exact number of rows: {n_rows}')\n",
    "df_tmp = pd.read_csv(CSV_PATH, nrows=5)\n",
    "df_tmp.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {\n",
    "    #'Unique Key': 'float32',\n",
    "              'Complaint Type': 'category', \n",
    "              'Longitude': 'float32',\n",
    "              'Latitude': 'float32',\n",
    "#              'Incident Zip': 'int',\n",
    "#              'Created Date': 'str',\n",
    "#              'Closed Date': 'str',\n",
    "\n",
    "        }\n",
    "cols = list(types.keys())\n",
    "chunksize = 5_000_000\n",
    "\n",
    "df_list = [] # list to hold the batch dataframe\n",
    "\n",
    "def process_date(df_chunk, key):\n",
    "    df_chunk[key] = df_chunk[key].str.slice(0, 16)\n",
    "    #df_chunk[key] = pd.to_datetime(df_chunk[key], utc=True, format='%Y-%m-%d %H:%M')\n",
    "    \n",
    "for df_chunk in tqdm(pd.read_csv(CSV_PATH, usecols=cols, dtype=types, chunksize=chunksize)):\n",
    "    # Neat trick from https://www.kaggle.com/btyuhas/bayesian-optimization-with-xgboost\n",
    "    # Using parse_dates would be much slower!\n",
    "#    process_date(df_chunk, 'Closed Date')\n",
    "#    process_date(df_chunk, 'Created Date')\n",
    "    df_list.append(df_chunk) \n",
    "\n",
    "    \n",
    "pdf = pd.concat(df_list)\n",
    "\n",
    "# Delete the dataframe list to release memory\n",
    "del df_list\n",
    "\n",
    "# See what we have loaded\n",
    "pdf.info()\n",
    "#takes 1:30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 2000\n",
    "\n",
    "counts = pdf['Complaint Type'].value_counts()\n",
    "print(counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "APERTURE_SIZE = 9\n",
    "hex_col = 'hex'+str(APERTURE_SIZE)\n",
    "\n",
    "\n",
    "pdf[hex_col] = 0\n",
    "import json\n",
    "\n",
    "print(1)\n",
    "def binRow(df311):\n",
    "    # find hexs containing the points\n",
    "    df311[hex_col] = df311.apply(lambda x: h3.geo_to_h3(x.Latitude,x.Longitude,APERTURE_SIZE),1)\n",
    "\n",
    "    # aggregate the points\n",
    "    df311g = df311.groupby(hex_col).size()#.to_frame('cnt').reset_index()\n",
    "\n",
    "    #find center of hex for visualization\n",
    "#     df311g['lat'] = df311g[hex_col].apply(lambda x: h3.h3_to_geo(x)[0])\n",
    "#     df311g['lng'] = df311g[hex_col].apply(lambda x: h3.h3_to_geo(x)[1])\n",
    "    return (df311g)\n",
    "\n",
    "\n",
    "def saveComplaint(complaint):\n",
    "    print(complaint)\n",
    "    data = pdf.loc[pdf['Complaint Type'] ==(complaint)]\n",
    "    binned = binRow(data)\n",
    "    complaint = complaint.replace(' ', '-').replace('/','-')\n",
    "    hi = [(hex, count)  for hex,count in binned.iteritems()]\n",
    "    with open('./data/'+complaint+'.json', 'w') as outfile: json.dump(hi, outfile)\n",
    "    \n",
    "stuff = ['Noise - Residential',                         \n",
    "'HEAT/HOT WATER' ,                              \n",
    "'Street Condition'   ,                           \n",
    "'Illegal Parking ',                              \n",
    "'Blocked Driveway'  ,                            \n",
    "'Street Light Condition' ,                       \n",
    "'HEATING'          ,                             \n",
    "'PLUMBING'     ,                                 \n",
    "'Water System'  ,                                \n",
    "'Noise - Street/Sidewalk' ,                      \n",
    "'GENERAL CONSTRUCTION'  ,                                                                \n",
    "'UNSANITARY CONDITION']                          \n",
    "for complaint in stuff:\n",
    "    saveComplaint(complaint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pdf.loc[pdf['Complaint Type'] ==('Noise - Residential')]\n",
    "# binned = binRow(data)\n",
    "for hex, row in binned.iteritems():\n",
    "    print(hex, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#automatically upload all csv to s3\n",
    "import boto3, os"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
